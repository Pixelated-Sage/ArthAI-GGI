# FinPredict ML â€” Development Progress

## Status: ðŸŸ¢ Core Implementation Complete

**Last Updated:** 2026-02-11

---

## Pipeline Overview

```
Data (TimescaleDB) â†’ Feature Engineering (TA-Lib) â†’ Sequences â†’ LSTM + XGBoost â†’ Hybrid Ensemble â†’ Evaluation
```

## Files Implemented

| File                         | Description                                | Status  |
| ---------------------------- | ------------------------------------------ | ------- |
| `config.py`                  | Config, hyperparameters, DB connection     | âœ… Done |
| `src/data_preparation.py`    | Load OHLCV from TimescaleDB, clean data    | âœ… Done |
| `src/feature_engineering.py` | 36 technical indicators via TA-Lib         | âœ… Done |
| `src/utils.py`               | DataScaler, split_data, helpers            | âœ… Done |
| `src/sequence_generator.py`  | LSTM 3D sequences + XGBoost flat features  | âœ… Done |
| `src/lstm_model.py`          | 2-layer LSTM with BatchNorm, EarlyStopping | âœ… Done |
| `src/xgboost_model.py`       | XGBoost with feature importance            | âœ… Done |
| `src/hybrid_model.py`        | Weighted ensemble + confidence scoring     | âœ… Done |
| `src/evaluation.py`          | RMSE, MAE, MAPE, RÂ², direction accuracy    | âœ… Done |
| `train.py`                   | Master training orchestrator (7 steps)     | âœ… Done |
| `inference.py`               | Model loading + prediction serving         | âœ… Done |

## Architecture

### LSTM Model

- 2 stacked LSTM layers (128 units each)
- Dropout (0.2) + BatchNormalization
- Dense head: 64 â†’ 32 â†’ 1
- Separate model per horizon (1d, 7d, 30d)
- EarlyStopping (patience=10) + ReduceLROnPlateau

### XGBoost Model

- 100 trees, max_depth=6, lr=0.1
- Lag features (1, 3, 5, 7, 14, 30 days)
- Rolling statistics (mean, std for windows 5, 10, 20)
- Separate model per horizon

### Hybrid Ensemble

- Weighted: w_lstm Ã— LSTM + w_xgb Ã— XGBoost
- Weights optimized via grid search on validation set
- Confidence = model agreement score (0.30 - 0.95)

### Features (36 indicators)

- **Price**: change (1d, 7d, 30d), HL spread, OC spread
- **Moving Averages**: SMA (5, 10, 20, 50, 200), EMA (12, 26, 50), distance from MAs
- **Momentum**: RSI, MACD (3 lines), Stochastic (K, D), ROC, CCI
- **Volatility**: Bollinger Bands (upper, mid, lower, width, position), ATR, HV
- **Volume**: SMA, ratio, OBV, A/D line

## Training Command

```bash
# Activate venv
source /data/venvs/FinpredictML/bin/activate

# Train all symbols
python ml/train.py

# Train single symbol
python ml/train.py --symbol AAPL

# Train with cached data (skip DB fetch)
python ml/train.py --symbol AAPL --skip-data

# Train specific symbols
python ml/train.py --symbols AAPL MSFT BTC
```

## Model Storage

```
/data/models/custom/finpredict/
â”œâ”€â”€ AAPL/
â”‚   â”œâ”€â”€ lstm_1d.keras          # LSTM for 1-day prediction
â”‚   â”œâ”€â”€ lstm_7d.keras          # LSTM for 7-day prediction
â”‚   â”œâ”€â”€ lstm_30d.keras         # LSTM for 30-day prediction
â”‚   â”œâ”€â”€ xgboost_1d.pkl         # XGBoost for 1-day
â”‚   â”œâ”€â”€ xgboost_7d.pkl         # XGBoost for 7-day
â”‚   â”œâ”€â”€ xgboost_30d.pkl        # XGBoost for 30-day
â”‚   â”œâ”€â”€ scaler.pkl             # MinMaxScaler state
â”‚   â”œâ”€â”€ hybrid_config.json     # Ensemble weights
â”‚   â”œâ”€â”€ evaluation_report.json # Metrics report
â”‚   â””â”€â”€ training_metadata.json # Training info
â”œâ”€â”€ MSFT/
â”‚   â””â”€â”€ ... (same structure)
â”œâ”€â”€ BTC/
â”‚   â””â”€â”€ ...
â””â”€â”€ training_progress.json     # Overall progress
```

## Target Metrics

| Metric             | Target | Grade         |
| ------------------ | ------ | ------------- |
| MAPE               | < 5%   | ðŸŸ¢ Excellent  |
| MAPE               | < 7%   | ðŸŸ¡ Good       |
| MAPE               | < 10%  | ðŸŸ  Acceptable |
| Direction Accuracy | > 60%  | âœ… Pass       |
| RÂ²                 | > 0.85 | Good          |

## Next Steps

- [x] **Run training pipeline** (Fixed `KeyError: 7` in hybrid evaluation)
- [x] **Integrate inference.py with backend FastAPI**
  - [x] Solved dependency mismatch using `subprocess` call to `FinpredictML` venv.
  - [x] Implemented robust `PredictionService` with JSON parsing.
- [ ] **Train all 8 symbols** (In Progress - Running in background)
- [ ] Tune hyperparameters (improve direction accuracy from ~50% to >60%)
- [ ] Frontend Integration (Connect React UI to API)
- [ ] Add sentiment analysis integration (FinGPT)
- [ ] Setup model retraining scheduler (Celery)
